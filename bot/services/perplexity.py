import httpx
from typing import List, Dict
from datetime import datetime

from bot.config import settings, PERPLEXITY_ENABLED
from bot.database.models import User, Answer, Question

from bot.prompts.base import BasePrompts
from bot.prompts.psychology import PsychologyPrompts
from .pdf_service import ReportGenerator


class PerplexityAIService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Perplexity AI"""

    def __init__(self):
        self.api_key = settings.PERPLEXITY_API_KEY
        self.model = settings.PERPLEXITY_MODEL
        self.api_url = "https://api.perplexity.ai/chat/completions"

        if not self.api_key:
            raise ValueError("PERPLEXITY_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö")

    def _prepare_user_data(self, user: User, questions: List[Question], answers: List[Answer]) -> str:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""

        # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç
        qa_pairs = []
        answer_dict = {ans.question_id: ans for ans in answers}

        for question in questions:
            answer = answer_dict.get(question.id)
            if answer and answer.text_answer:
                qa_pairs.append(f"""
                    –í–æ–ø—Ä–æ—Å {question.order_number}: {question.text}
                    –û—Ç–≤–µ—Ç: {answer.text_answer}
                    """)

        return "\n".join(qa_pairs)

    async def _make_api_request(self, messages: List[Dict]) -> Dict:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ –∫ Perplexity API"""

        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
            "User-Agent": "PRIZMA-AI-Psychologist/1.0"
        }

        payload = {
            "model": self.model,
            "messages": messages,
            "max_tokens": 4000,  # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Å –ø–∞–º—è—Ç—å—é (–±—ã–ª–æ 2000)
            "temperature": 0.7,  # –ë–∞–ª–∞–Ω—Å –º–µ–∂–¥—É –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å—é –∏ —Ç–æ—á–Ω–æ—Å—Ç—å—é
            "stream": False
        }

        async with httpx.AsyncClient(timeout=60.0) as client:
            response = await client.post(
                self.api_url,
                headers=headers,
                json=payload
            )

            if response.status_code != 200:
                raise Exception(
                    f"API Error {response.status_code}: {response.text}")

            result = response.json()

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Ç–≤–µ—Ç
            if "choices" in result and len(result["choices"]) > 0:
                content = result["choices"][0]["message"]["content"]
                usage = result.get("usage", {})

                return {
                    "content": content,
                    "usage": usage
                }
            else:
                raise Exception("–ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ –æ—Ç API")

    async def analyze_user_responses(self, user: User, questions: List[Question], answers: List[Answer]) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ –æ—Ç–≤–µ—Ç–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —á–µ—Ä–µ–∑ Perplexity AI —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–π –ø–∞–º—è—Ç—å—é"""

        # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        user_data = self._prepare_user_data(user, questions, answers)

        try:
            print(
                f"üß† –ó–∞–ø—É—Å–∫–∞–µ–º –ö–û–ù–¢–ï–ö–°–¢–ù–´–ô AI –∞–Ω–∞–ª–∏–∑ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user.telegram_id}...")

            # 1Ô∏è‚É£ –≠–¢–ê–ü: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è conversation —Å –±–∞–∑–æ–≤–æ–π —Ä–æ–ª—å—é
            conversation = []

            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–æ–ª—å —ç–∫—Å–ø–µ—Ä—Ç–∞-–ø—Å–∏—Ö–æ–ª–æ–≥–∞
            conversation.append({
                "role": "system",
                "content": BasePrompts.get_common_context()
            })

            # –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è
            conversation.append({
                "role": "user",
                "content": f"""–í–æ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞:

{user_data}

–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∏–∑—É—á–∏—Ç–µ —ç—Ç–∏ –æ—Ç–≤–µ—Ç—ã –∏ –ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –∫ —Å–æ–∑–¥–∞–Ω–∏—é –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞. –í–ê–ñ–ù–û: –í –¥–∞–ª—å–Ω–µ–π—à–∏—Ö –æ—Ç–≤–µ—Ç–∞—Ö –æ–±—Ä–∞—â–∞–π—Ç–µ—Å—å –∫ —á–µ–ª–æ–≤–µ–∫—É –Ω–∞–ø—Ä—è–º—É—é —á–µ—Ä–µ–∑ "–í–´", "–í–ê–®–ò", "–í–ê–ú" - –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å–ª–æ–≤–∞ "–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å" –∏–ª–∏ "–∫–ª–∏–µ–Ω—Ç"."""
            })

            # 2Ô∏è‚É£ –≠–¢–ê–ü: –ü–µ—Ä–≤–∏—á–Ω–æ–µ –∏–∑—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
            print(f"üîÑ –≠—Ç–∞–ø 1: –ò–ò –∏–∑—É—á–∞–µ—Ç –æ—Ç–≤–µ—Ç—ã...")
            initial_response = await self._make_api_request(conversation)

            conversation.append({
                "role": "assistant",
                "content": initial_response["content"]
            })

            print(
                f"üìù –ü–µ—Ä–≤–∏—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ–ª—É—á–µ–Ω: {len(initial_response['content'])} —Å–∏–º–≤–æ–ª–æ–≤")

            # 3Ô∏è‚É£ –≠–¢–ê–ü: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–∞–∂–¥–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
            results = {}
            page_names = {
                "page3": "–¢–∏–ø –ª–∏—á–Ω–æ—Å—Ç–∏",
                "page4": "–ú—ã—à–ª–µ–Ω–∏–µ –∏ —Ä–µ—à–µ–Ω–∏—è",
                "page5": "–û–≥—Ä–∞–Ω–∏—á–∏–≤–∞—é—â–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã"
            }

            for page_type in ["page3", "page4", "page5"]:
                print(
                    f"üîÑ –≠—Ç–∞–ø {len(results) + 2}: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã '{page_names[page_type]}'...")

                # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
                page_prompt = self._get_page_specific_prompt(page_type)
                conversation.append({
                    "role": "user",
                    "content": page_prompt
                })

                # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç —Å –ø–æ–ª–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π
                page_response = await self._make_api_request(conversation)

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                results[page_type] = page_response

                # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è —Å–ª–µ–¥—É—é—â–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
                conversation.append({
                    "role": "assistant",
                    "content": page_response["content"]
                })

                content_length = len(page_response["content"])
                print(
                    f"üìù {page_names[page_type]}: –ø–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –¥–ª–∏–Ω–æ–π {content_length} —Å–∏–º–≤–æ–ª–æ–≤")

            # 4Ô∏è‚É£ –≠–¢–ê–ü: –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            page3_length = len(results["page3"]["content"])
            page4_length = len(results["page4"]["content"])
            page5_length = len(results["page5"]["content"])

            print(
                f"üìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ö–û–ù–¢–ï–ö–°–¢–ù–û–ì–û –ê–ù–ê–õ–ò–ó–ê –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user.telegram_id}:")
            print(f"   –°—Ç—Ä–∞–Ω–∏—Ü–∞ 3 (–¢–∏–ø –ª–∏—á–Ω–æ—Å—Ç–∏): {page3_length} —Å–∏–º–≤–æ–ª–æ–≤")
            print(
                f"   –°—Ç—Ä–∞–Ω–∏—Ü–∞ 4 (–ú—ã—à–ª–µ–Ω–∏–µ –∏ —Ä–µ—à–µ–Ω–∏—è): {page4_length} —Å–∏–º–≤–æ–ª–æ–≤")
            print(
                f"   –°—Ç—Ä–∞–Ω–∏—Ü–∞ 5 (–û–≥—Ä–∞–Ω–∏—á–∏–≤–∞—é—â–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã): {page5_length} —Å–∏–º–≤–æ–ª–æ–≤")
            print(
                f"   –û–±—â–∏–π –æ–±—ä–µ–º: {page3_length + page4_length + page5_length} —Å–∏–º–≤–æ–ª–æ–≤")
            print(
                f"   üìû –í—Å–µ–≥–æ –æ–±—Ä–∞—â–µ–Ω–∏–π –∫ –ò–ò: {len(results) + 1} (1 –ø–µ—Ä–≤–∏—á–Ω—ã–π + 3 —Å—Ç—Ä–∞–Ω–∏—Ü—ã)")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç—Ä–µ–±—É–µ–º–æ–º—É –¥–∏–∞–ø–∞–∑–æ–Ω—É
            target_min, target_max = 1900, 2000

            for page_type, page_name in page_names.items():
                length = len(results[page_type]["content"])
                if length < target_min:
                    print(
                        f"‚ö†Ô∏è {page_name}: {length} —Å–∏–º–≤–æ–ª–æ–≤ - –ú–ï–ù–¨–®–ï —Ü–µ–ª–µ–≤–æ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ ({target_min}-{target_max})")
                elif length > target_max:
                    print(
                        f"‚ö†Ô∏è {page_name}: {length} —Å–∏–º–≤–æ–ª–æ–≤ - –ë–û–õ–¨–®–ï —Ü–µ–ª–µ–≤–æ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ ({target_min}-{target_max})")
                else:
                    print(
                        f"‚úÖ {page_name}: {length} —Å–∏–º–≤–æ–ª–æ–≤ - –í –¶–ï–õ–ï–í–û–ú –¥–∏–∞–ø–∞–∑–æ–Ω–µ ({target_min}-{target_max})")

            return {
                "success": True,
                "page3_analysis": results["page3"]["content"],
                "page4_analysis": results["page4"]["content"],
                "page5_analysis": results["page5"]["content"],
                # –ù–æ–≤–æ–µ: –ø–µ—Ä–≤–∏—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑
                "initial_analysis": initial_response["content"],
                "usage": {
                    "initial": initial_response.get("usage", {}),
                    "page3": results["page3"].get("usage", {}),
                    "page4": results["page4"].get("usage", {}),
                    "page5": results["page5"].get("usage", {})
                },
                "character_stats": {
                    "page3_length": page3_length,
                    "page4_length": page4_length,
                    "page5_length": page5_length,
                    "total_length": page3_length + page4_length + page5_length,
                    "initial_length": len(initial_response["content"]),
                    "context_enabled": True
                },
                "timestamp": datetime.utcnow().isoformat()
            }

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–º –∞–Ω–∞–ª–∏–∑–µ: {e}")
            return {
                "success": False,
                "error": str(e),
                "timestamp": datetime.utcnow().isoformat()
            }

    def _get_page_specific_prompt(self, page_type: str) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏–∑ –º–æ–¥—É–ª—è psychology.py"""
        prompts_map = PsychologyPrompts.get_context_prompts_map()
        
        if page_type not in prompts_map:
            raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {page_type}")
        
        return prompts_map[page_type]()


class AIAnalysisService:
    """–û—Å–Ω–æ–≤–Ω–æ–π —Å–µ—Ä–≤–∏—Å –¥–ª—è AI –∞–Ω–∞–ª–∏–∑–∞"""

    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–∞ –¥–ª—è AI –∞–Ω–∞–ª–∏–∑–∞"""
        self.perplexity_enabled = PERPLEXITY_ENABLED

        if self.perplexity_enabled:
            try:
                self.ai_service = PerplexityAIService()
            except Exception as e:
                print(
                    f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Perplexity AI (–æ—Ç–∫–ª—é—á–∞–µ–º): {e}")
                self.perplexity_enabled = False
                self.ai_service = None
        else:
            self.ai_service = None

        self.report_generator = ReportGenerator()

    async def generate_psychological_report(self, user: User, questions: List[Question], answers: List[Answer]) -> Dict:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–ª–Ω–æ–≥–æ –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –æ—Ç—á–µ—Ç–∞ —Å —Ç—Ä–µ–º—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞"""

        try:
            if self.perplexity_enabled and self.ai_service:
                # üß† –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å –ø–∞–º—è—Ç—å—é (–µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π —Ä–µ–∂–∏–º)
                print(
                    f"üß† –ó–∞–ø—É—Å–∫–∞–µ–º AI –∞–Ω–∞–ª–∏–∑ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user.telegram_id}...")
                analysis_result = await self.ai_service.analyze_user_responses(user, questions, answers)

                if not analysis_result.get("success"):
                    print(f"‚ö†Ô∏è AI –∞–Ω–∞–ª–∏–∑ –Ω–µ—É–¥–∞—á–µ–Ω, —Å–æ–∑–¥–∞–µ–º –æ—Ç—á–µ—Ç –±–µ–∑ –∞–Ω–∞–ª–∏–∑–∞")
                    analysis_result = self._create_fallback_analysis()
            else:
                print(
                    f"‚ÑπÔ∏è Perplexity AI –æ—Ç–∫–ª—é—á–µ–Ω, —Å–æ–∑–¥–∞–µ–º –æ—Ç—á–µ—Ç –±–µ–∑ –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user.telegram_id}")
                analysis_result = self._create_fallback_analysis()

            # –°–æ–∑–¥–∞–µ–º PDF –æ—Ç—á–µ—Ç
            print(f"üìÑ –°–æ–∑–¥–∞–µ–º PDF –æ—Ç—á–µ—Ç...")
            report_filepath = self.report_generator.create_pdf_report(
                user, analysis_result)

            print(f"‚úÖ –û—Ç—á–µ—Ç —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω: {report_filepath}")

            return {
                "success": True,
                "page3_analysis": analysis_result["page3_analysis"],
                "page4_analysis": analysis_result["page4_analysis"],
                "page5_analysis": analysis_result["page5_analysis"],
                "report_file": report_filepath,
                "usage": analysis_result.get("usage", {}),
                "character_stats": analysis_result.get("character_stats", {}),
                "timestamp": analysis_result["timestamp"]
            }

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–∞: {e}")
            return {
                "success": False,
                "error": str(e),
                "stage": "general"
            }

    def _create_fallback_analysis(self) -> Dict:
        """–°–æ–∑–¥–∞—Ç—å –±–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ –±–µ–∑ –ò–ò"""
        timestamp = datetime.utcnow().isoformat()

        # –°–æ–∑–¥–∞–µ–º fallback —Ç–µ–∫—Å—Ç—ã
        page3_analysis = "–í–∞—à–∏ –æ—Ç–≤–µ—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –ª–∏—á–Ω–æ—Å—Ç–∏. –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –±—É–¥–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω –≤ –±–ª–∏–∂–∞–π—à–µ–µ –≤—Ä–µ–º—è."
        page4_analysis = "–ù–∞ –æ—Å–Ω–æ–≤–µ –≤–∞—à–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤ –º–æ–∂–Ω–æ –≤—ã–¥–µ–ª–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–ª—é—á–µ–≤—ã—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –≤–∞—à–µ–≥–æ –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–æ—Ñ–∏–ª—è."
        page5_analysis = "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Ä–∞–∑–≤–∏—Ç–∏—é –∏ —Å–∞–º–æ—Å–æ–≤–µ—Ä—à–µ–Ω—Å—Ç–≤–æ–≤–∞–Ω–∏—é –±—É–¥—É—Ç –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω—ã –≤ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–π –≤–µ—Ä—Å–∏–∏ –æ—Ç—á–µ—Ç–∞."

        # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è fallback –∞–Ω–∞–ª–∏–∑–∞
        page3_length = len(page3_analysis)
        page4_length = len(page4_analysis)
        page5_length = len(page5_analysis)

        print(f"üìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê –°–ò–ú–í–û–õ–û–í –¥–ª—è fallback –∞–Ω–∞–ª–∏–∑–∞:")
        print(f"   –°—Ç—Ä–∞–Ω–∏—Ü–∞ 3 (–¢–∏–ø –ª–∏—á–Ω–æ—Å—Ç–∏): {page3_length} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"   –°—Ç—Ä–∞–Ω–∏—Ü–∞ 4 (–ú—ã—à–ª–µ–Ω–∏–µ –∏ —Ä–µ—à–µ–Ω–∏—è): {page4_length} —Å–∏–º–≤–æ–ª–æ–≤")
        print(
            f"   –°—Ç—Ä–∞–Ω–∏—Ü–∞ 5 (–û–≥—Ä–∞–Ω–∏—á–∏–≤–∞—é—â–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã): {page5_length} —Å–∏–º–≤–æ–ª–æ–≤")
        print(
            f"   –û–±—â–∏–π –æ–±—ä–µ–º: {page3_length + page4_length + page5_length} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è fallback –∞–Ω–∞–ª–∏–∑ - –≤—Å–µ —Ç–µ–∫—Å—Ç—ã –ù–ï —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —Ü–µ–ª–µ–≤–æ–º—É –æ–±—ä–µ–º—É 1900-2000 —Å–∏–º–≤–æ–ª–æ–≤")

        return {
            "success": True,
            "page3_analysis": page3_analysis,
            "page4_analysis": page4_analysis,
            "page5_analysis": page5_analysis,
            "usage": {},
            "character_stats": {
                "page3_length": page3_length,
                "page4_length": page4_length,
                "page5_length": page5_length,
                "total_length": page3_length + page4_length + page5_length,
                "is_fallback": True
            },
            "timestamp": timestamp
        }
