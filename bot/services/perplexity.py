import httpx
from typing import List, Dict
from datetime import datetime

from bot.config import settings, PERPLEXITY_ENABLED
from bot.database.models import User, Answer, Question
from bot.prompts import PsychologyPrompts
from .pdf_service import ReportGenerator


class PerplexityAIService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Perplexity AI"""
    
    def __init__(self):
        self.api_key = settings.PERPLEXITY_API_KEY
        self.model = settings.PERPLEXITY_MODEL
        self.api_url = "https://api.perplexity.ai/chat/completions"
        
        if not self.api_key:
            raise ValueError("PERPLEXITY_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö")
    


    async def analyze_user_responses(self, user: User, questions: List[Question], answers: List[Answer]) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ –æ—Ç–≤–µ—Ç–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —á–µ—Ä–µ–∑ Perplexity AI –¥–ª—è –≤—Å–µ—Ö —Ç—Ä–µ—Ö —Å—Ç—Ä–∞–Ω–∏—Ü"""
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        user_data = self._prepare_user_data(user, questions, answers)
        
        try:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑ –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            print(f"üìä –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user.telegram_id}...")
            
            page3_result = await self._generate_page_analysis(user, user_data, "page3")
            page4_result = await self._generate_page_analysis(user, user_data, "page4") 
            page5_result = await self._generate_page_analysis(user, user_data, "page5")
            
            # –õ–æ–≥–∏—Ä—É–µ–º –æ–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å–∏–º–≤–æ–ª–æ–≤
            page3_length = len(page3_result.get("content", ""))
            page4_length = len(page4_result.get("content", ""))
            page5_length = len(page5_result.get("content", ""))
            
            print(f"üìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê –°–ò–ú–í–û–õ–û–í –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user.telegram_id}:")
            print(f"   –°—Ç—Ä–∞–Ω–∏—Ü–∞ 3 (–¢–∏–ø –ª–∏—á–Ω–æ—Å—Ç–∏): {page3_length} —Å–∏–º–≤–æ–ª–æ–≤")
            print(f"   –°—Ç—Ä–∞–Ω–∏—Ü–∞ 4 (–ú—ã—à–ª–µ–Ω–∏–µ –∏ —Ä–µ—à–µ–Ω–∏—è): {page4_length} —Å–∏–º–≤–æ–ª–æ–≤") 
            print(f"   –°—Ç—Ä–∞–Ω–∏—Ü–∞ 5 (–û–≥—Ä–∞–Ω–∏—á–∏–≤–∞—é—â–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã): {page5_length} —Å–∏–º–≤–æ–ª–æ–≤")
            print(f"   –û–±—â–∏–π –æ–±—ä–µ–º: {page3_length + page4_length + page5_length} —Å–∏–º–≤–æ–ª–æ–≤")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç—Ä–µ–±—É–µ–º–æ–º—É –¥–∏–∞–ø–∞–∑–æ–Ω—É 1900-2000 —Å–∏–º–≤–æ–ª–æ–≤
            target_min, target_max = 1900, 2000
            
            for page_name, length in [("–°—Ç—Ä–∞–Ω–∏—Ü–∞ 3", page3_length), ("–°—Ç—Ä–∞–Ω–∏—Ü–∞ 4", page4_length), ("–°—Ç—Ä–∞–Ω–∏—Ü–∞ 5", page5_length)]:
                if length < target_min:
                    print(f"‚ö†Ô∏è {page_name}: {length} —Å–∏–º–≤–æ–ª–æ–≤ - –ú–ï–ù–¨–®–ï —Ü–µ–ª–µ–≤–æ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ ({target_min}-{target_max})")
                elif length > target_max:
                    print(f"‚ö†Ô∏è {page_name}: {length} —Å–∏–º–≤–æ–ª–æ–≤ - –ë–û–õ–¨–®–ï —Ü–µ–ª–µ–≤–æ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ ({target_min}-{target_max})")
                else:
                    print(f"‚úÖ {page_name}: {length} —Å–∏–º–≤–æ–ª–æ–≤ - –í –¶–ï–õ–ï–í–û–ú –¥–∏–∞–ø–∞–∑–æ–Ω–µ ({target_min}-{target_max})")
            
            return {
                "success": True,
                "page3_analysis": page3_result.get("content", ""),
                "page4_analysis": page4_result.get("content", ""),
                "page5_analysis": page5_result.get("content", ""),
                "usage": {
                    "page3": page3_result.get("usage", {}),
                    "page4": page4_result.get("usage", {}),
                    "page5": page5_result.get("usage", {})
                },
                "character_stats": {
                    "page3_length": page3_length,
                    "page4_length": page4_length,
                    "page5_length": page5_length,
                    "total_length": page3_length + page4_length + page5_length
                },
                "timestamp": datetime.utcnow().isoformat()
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "timestamp": datetime.utcnow().isoformat()
            }

    async def _generate_page_analysis(self, user: User, user_data: str, page_type: str) -> Dict:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ–º–ø—Ç –∏–∑ –º–æ–¥—É–ª—è –ø—Ä–æ–º–ø—Ç–æ–≤
        prompts_map = PsychologyPrompts.get_prompts_map()
        if page_type not in prompts_map:
            raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {page_type}")
        
        system_prompt = prompts_map[page_type]()
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç –∏–∑ —à–∞–±–ª–æ–Ω–∞
        user_prompt = PsychologyPrompts.get_user_info_template().format(
            user_data=user_data
        )
        
        messages = [
            {
                "role": "system",
                "content": system_prompt
            },
            {
                "role": "user",
                "content": user_prompt
            }
        ]
        
        print(f"üîÑ –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑ –¥–ª—è {page_type}...")
        result = await self._make_api_request(messages)
        
        # –õ–æ–≥–∏—Ä—É–µ–º –¥–ª–∏–Ω—É –æ—Ç–≤–µ—Ç–∞ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        content_length = len(result.get("content", ""))
        page_names = {
            "page3": "–¢–∏–ø –ª–∏—á–Ω–æ—Å—Ç–∏", 
            "page4": "–ú—ã—à–ª–µ–Ω–∏–µ –∏ —Ä–µ—à–µ–Ω–∏—è",
            "page5": "–û–≥—Ä–∞–Ω–∏—á–∏–≤–∞—é—â–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã"
        }
        page_name = page_names.get(page_type, page_type)
        
        print(f"üìù {page_name}: –ø–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –¥–ª–∏–Ω–æ–π {content_length} —Å–∏–º–≤–æ–ª–æ–≤")
        
        return result

    def _prepare_user_data(self, user: User, questions: List[Question], answers: List[Answer]) -> str:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
        
        # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç
        qa_pairs = []
        answer_dict = {ans.question_id: ans for ans in answers}
        
        for question in questions:
            answer = answer_dict.get(question.id)
            if answer and answer.text_answer:
                qa_pairs.append(f"""
–í–æ–ø—Ä–æ—Å {question.order_number}: {question.text}
–û—Ç–≤–µ—Ç: {answer.text_answer}
""")
        
        return "\n".join(qa_pairs)
    
    async def _make_api_request(self, messages: List[Dict]) -> Dict:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ –∫ Perplexity API"""
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
            "User-Agent": "PRIZMA-AI-Psychologist/1.0"
        }
        
        payload = {
            "model": self.model,
            "messages": messages,
            "max_tokens": 2000,  # –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
            "temperature": 0.7,  # –ë–∞–ª–∞–Ω—Å –º–µ–∂–¥—É –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å—é –∏ —Ç–æ—á–Ω–æ—Å—Ç—å—é
            "stream": False
        }
        
        async with httpx.AsyncClient(timeout=60.0) as client:
            response = await client.post(
                self.api_url,
                headers=headers,
                json=payload
            )
            
            if response.status_code != 200:
                raise Exception(f"API Error {response.status_code}: {response.text}")
            
            result = response.json()
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Ç–≤–µ—Ç
            if "choices" in result and len(result["choices"]) > 0:
                content = result["choices"][0]["message"]["content"]
                usage = result.get("usage", {})
                
                return {
                    "content": content,
                    "usage": usage
                }
            else:
                raise Exception("–ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ –æ—Ç API")




class AIAnalysisService:
    """–û—Å–Ω–æ–≤–Ω–æ–π —Å–µ—Ä–≤–∏—Å –¥–ª—è AI –∞–Ω–∞–ª–∏–∑–∞"""
    
    def __init__(self):
        self.perplexity_enabled = PERPLEXITY_ENABLED
        if self.perplexity_enabled:
            try:
                self.ai_service = PerplexityAIService()
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Perplexity AI (–æ—Ç–∫–ª—é—á–∞–µ–º): {e}")
                self.perplexity_enabled = False
                self.ai_service = None
        else:
            self.ai_service = None
        
        self.report_generator = ReportGenerator()
    
    async def generate_psychological_report(self, user: User, questions: List[Question], answers: List[Answer]) -> Dict:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–ª–Ω–æ–≥–æ –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –æ—Ç—á–µ—Ç–∞ —Å —Ç—Ä–µ–º—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞"""
        
        try:
            if self.perplexity_enabled and self.ai_service:
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç—ã —á–µ—Ä–µ–∑ AI –¥–ª—è –≤—Å–µ—Ö —Ç—Ä–µ—Ö —Å—Ç—Ä–∞–Ω–∏—Ü
                print(f"üß† –ó–∞–ø—É—Å–∫–∞–µ–º AI –∞–Ω–∞–ª–∏–∑ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user.telegram_id}...")
                analysis_result = await self.ai_service.analyze_user_responses(user, questions, answers)
                
                if not analysis_result.get("success"):
                    print(f"‚ö†Ô∏è AI –∞–Ω–∞–ª–∏–∑ –Ω–µ—É–¥–∞—á–µ–Ω, —Å–æ–∑–¥–∞–µ–º –æ—Ç—á–µ—Ç –±–µ–∑ –∞–Ω–∞–ª–∏–∑–∞")
                    analysis_result = self._create_fallback_analysis()
            else:
                print(f"‚ÑπÔ∏è Perplexity AI –æ—Ç–∫–ª—é—á–µ–Ω, —Å–æ–∑–¥–∞–µ–º –æ—Ç—á–µ—Ç –±–µ–∑ –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user.telegram_id}")
                analysis_result = self._create_fallback_analysis()
            
            # –°–æ–∑–¥–∞–µ–º PDF –æ—Ç—á–µ—Ç
            print(f"üìÑ –°–æ–∑–¥–∞–µ–º PDF –æ—Ç—á–µ—Ç...")
            report_filepath = self.report_generator.create_pdf_report(user, analysis_result)
            
            print(f"‚úÖ –û—Ç—á–µ—Ç —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω: {report_filepath}")
            
            return {
                "success": True,
                "page3_analysis": analysis_result["page3_analysis"],
                "page4_analysis": analysis_result["page4_analysis"], 
                "page5_analysis": analysis_result["page5_analysis"],
                "report_file": report_filepath,
                "usage": analysis_result.get("usage", {}),
                "character_stats": analysis_result.get("character_stats", {}),
                "timestamp": analysis_result["timestamp"]
            }
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–∞: {e}")
            return {
                "success": False,
                "error": str(e),
                "stage": "general"
            }
    
    def _create_fallback_analysis(self) -> Dict:
        """–°–æ–∑–¥–∞—Ç—å –±–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ –±–µ–∑ –ò–ò"""
        timestamp = datetime.utcnow().isoformat()
        
        # –°–æ–∑–¥–∞–µ–º fallback —Ç–µ–∫—Å—Ç—ã
        page3_analysis = "–í–∞—à–∏ –æ—Ç–≤–µ—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –ª–∏—á–Ω–æ—Å—Ç–∏. –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –±—É–¥–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω –≤ –±–ª–∏–∂–∞–π—à–µ–µ –≤—Ä–µ–º—è."
        page4_analysis = "–ù–∞ –æ—Å–Ω–æ–≤–µ –≤–∞—à–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤ –º–æ–∂–Ω–æ –≤—ã–¥–µ–ª–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–ª—é—á–µ–≤—ã—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –≤–∞—à–µ–≥–æ –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–æ—Ñ–∏–ª—è."
        page5_analysis = "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Ä–∞–∑–≤–∏—Ç–∏—é –∏ —Å–∞–º–æ—Å–æ–≤–µ—Ä—à–µ–Ω—Å—Ç–≤–æ–≤–∞–Ω–∏—é –±—É–¥—É—Ç –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω—ã –≤ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–π –≤–µ—Ä—Å–∏–∏ –æ—Ç—á–µ—Ç–∞."
        
        # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è fallback –∞–Ω–∞–ª–∏–∑–∞
        page3_length = len(page3_analysis)
        page4_length = len(page4_analysis)
        page5_length = len(page5_analysis)
        
        print(f"üìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê –°–ò–ú–í–û–õ–û–í –¥–ª—è fallback –∞–Ω–∞–ª–∏–∑–∞:")
        print(f"   –°—Ç—Ä–∞–Ω–∏—Ü–∞ 3 (–¢–∏–ø –ª–∏—á–Ω–æ—Å—Ç–∏): {page3_length} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"   –°—Ç—Ä–∞–Ω–∏—Ü–∞ 4 (–ú—ã—à–ª–µ–Ω–∏–µ –∏ —Ä–µ—à–µ–Ω–∏—è): {page4_length} —Å–∏–º–≤–æ–ª–æ–≤") 
        print(f"   –°—Ç—Ä–∞–Ω–∏—Ü–∞ 5 (–û–≥—Ä–∞–Ω–∏—á–∏–≤–∞—é—â–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã): {page5_length} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"   –û–±—â–∏–π –æ–±—ä–µ–º: {page3_length + page4_length + page5_length} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è fallback –∞–Ω–∞–ª–∏–∑ - –≤—Å–µ —Ç–µ–∫—Å—Ç—ã –ù–ï —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —Ü–µ–ª–µ–≤–æ–º—É –æ–±—ä–µ–º—É 1900-2000 —Å–∏–º–≤–æ–ª–æ–≤")
        
        return {
            "success": True,
            "page3_analysis": page3_analysis,
            "page4_analysis": page4_analysis,
            "page5_analysis": page5_analysis,
            "usage": {},
            "character_stats": {
                "page3_length": page3_length,
                "page4_length": page4_length,
                "page5_length": page5_length,
                "total_length": page3_length + page4_length + page5_length,
                "is_fallback": True
            },
            "timestamp": timestamp
        } 